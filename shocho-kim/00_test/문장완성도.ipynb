{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch 버전: 2.5.1+cu124\n",
      "CUDA 사용 가능 여부: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch 버전:\", torch.__version__)\n",
    "print(\"CUDA 사용 가능 여부:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentencePiece 설치 완료!\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece\n",
    "print(\"SentencePiece 설치 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아니 진짜 뭐 하냐고.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "# T5 모델 로드\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"j5ng/et5-typos-corrector\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"j5ng/et5-typos-corrector\")\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"mps:0\" if torch.cuda.is_available() else \"cpu\" # for mac m1\n",
    "\n",
    "model = model.to(device) \n",
    "\n",
    "# 예시 입력 문장\n",
    "input_text = \"아늬 진짜 무ㅓ하냐고\"\n",
    "\n",
    "# 입력 문장 인코딩\n",
    "input_encoding = tokenizer(\"맞춤법을 고쳐주세요: \" + input_text, return_tensors=\"pt\")\n",
    "\n",
    "input_ids = input_encoding.input_ids.to(device)\n",
    "attention_mask = input_encoding.attention_mask.to(device)\n",
    "\n",
    "# T5 모델 출력 생성\n",
    "output_encoding = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    attention_mask=attention_mask,\n",
    "    max_length=128,\n",
    "    num_beams=5,\n",
    "    early_stopping=True,\n",
    ")\n",
    "\n",
    "# 출력 문장 디코딩\n",
    "output_text = tokenizer.decode(output_encoding[0], skip_special_tokens=True)\n",
    "\n",
    "# 결과 출력\n",
    "print(output_text) # 아니 진짜 뭐 하냐고.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "완전 어이없네 진짜 ᄏᄏᄏᄏ.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, pipeline\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained('j5ng/et5-typos-corrector')\n",
    "tokenizer = T5Tokenizer.from_pretrained('j5ng/et5-typos-corrector')\n",
    "\n",
    "typos_corrector = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=0 if torch.cuda.is_available() else -1,\n",
    "    framework=\"pt\",\n",
    ")\n",
    "\n",
    "input_text = \"완죤 어이업ㅅ네진쨬ㅋㅋㅋ\"\n",
    "output_text = typos_corrector(\"맞춤법을 고쳐주세요: \" + input_text,\n",
    "            max_length=128,\n",
    "            num_beams=5,\n",
    "            early_stopping=True)[0]['generated_text']\n",
    "\n",
    "print(output_text) # 완전 어이없네 진짜 ᄏᄏᄏᄏ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나에게 가혹한 이 겨울이\n",
      "지친 맘을 달래줄 수는 없는걸까요\n",
      "아무것도 모른 채 나 혼자 걸어가는 \n",
      "나의 작은 떨림이 아직 남아서\n",
      "이제서야 울음을 터뜨렸어요 \n",
      "나를 생각해 난\n",
      "널 보는 눈이 슬퍼져도\n",
      "나의 말을 따라 걷고 있어요\n",
      "네게 다가갈래요 사랑스런 그대여\n",
      "울지 말아요 나는 그댈 더 사랑한대요\n",
      "나를 생각하며\n",
      "눈물 흘리지 않게 조심스레 눈을 감고서\n",
      "그대와 내가 나눈 모든 얘기\n",
      "오랜 시간을 흘러 가며 나눴던 많은 추억들\n",
      "다 잊은 채로 내게 또 미안하게 한다\n",
      "내 곁에 꼭 머물러줘\n",
      "조금 서툴지만 조금씩 너도 사랑을 찾아가는 걸 \n",
      "두려워 하지 말길 네가 알아주기를 원해요\n",
      "끝나지 않을 슬픔이 여기서도 찾아와\n",
      "기꺼이 날 위로하려 해도\n",
      "날 떠나지 마 널 그리워하지 말라고 했던 것처럼\n",
      "온 세상이 지쳐있단 것을 알면서 더욱 흔들리고\n",
      "\n",
      "['나에게 가혹한 이 겨울이', '지친 맘을 달래줄 수는 없는걸까요', '아무것도 모른 채 나 혼자 걸어가는 ', '나의 작은 떨림이 아직 남아서', '이제서야 울음을 터뜨렸어요 ', '나를 생각해 난', '널 보는 눈이 슬퍼져도', '나의 말을 따라 걷고 있어요', '네게 다가갈래요 사랑스런 그대여', '울지 말아요 나는 그댈 더 사랑한대요', '나를 생각하며', '눈물 흘리지 않게 조심스레 눈을 감고서', '그대와 내가 나눈 모든 얘기', '오랜 시간을 흘러 가며 나눴던 많은 추억들', '다 잊은 채로 내게 또 미안하게 한다', '내 곁에 꼭 머물러줘', '조금 서툴지만 조금씩 너도 사랑을 찾아가는 걸 ', '두려워 하지 말길 네가 알아주기를 원해요', '끝나지 않을 슬픔이 여기서도 찾아와', '기꺼이 날 위로하려 해도', '날 떠나지 마 널 그리워하지 말라고 했던 것처럼', '온 세상이 지쳐있단 것을 알면서 더욱 흔들리고', '']\n"
     ]
    }
   ],
   "source": [
    "with open(\"../../1.데이터모음/generated_lyrics/generated_lyrics_2025-01-31_07-25-44.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    data = file.read()\n",
    "\n",
    "# \\n 기준으로 문장 나누기\n",
    "sentences = data.split(\"\\n\")\n",
    "\n",
    "\n",
    "print(data)\n",
    "\n",
    "\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가혹한 이 겨울이.\n",
      "\" 문장 비문 여부 지친 맘을 달래줄 수는 없는 걸까요?\".\n",
      "\" 문장 비문 여부 아무것도 모른 채 나 혼자 걸어가는\" 문장 비문 여부 아무것도 모른 채 나 혼자 걸어가는.\n",
      "나의 작은 떨림이 아직 남아서.\n",
      "문장 비문 여부 이제서야 울음을 터뜨렸어요.\n",
      "난 문장 비문 여부 나를 생각해 난.\n",
      "\" 문장 비문 여부 널 보는 눈이 슬퍼져도\".\n",
      "\" 문장 비문 여부 나의 말을 따라 걷고 있어요\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" 문장 비문 여부 네 게 다가갈래요 사랑스런 그대여\".\n",
      "울지 말아요 나는 그댈 더 사랑한대요.\n",
      "\" 문장 비문 여부 나를 생각하며\".\n",
      "\" 문장 비문 여부 눈물 흘리지 않게 조심스레 눈을 감고서.\n",
      "구문 비문 여부 그대와 내가 나는 모든 얘기.\n",
      "\" 문장 비문 여부 오랜 시간을 흘러 가며 나눴던 많은 추억들.\n",
      "\" 문장 비문 여부 다 잊은 채로 내게 또 미안하게 한다\".\n",
      "\" 문장 비문 여부 내 곁에 꼭 머물러줘\".\n",
      "서툴지만 조금씩 너도 사랑을 찾아가는 걸.\n",
      "\" 문장 비문 여부 두려워하지 말길 네가 알아주기를 원해요\".\n",
      "\" 문장 비문 여부 끝나지 않을 슬픔이 여기서도 찾아와.\n",
      "전 문장 비문 여부 기꺼이 날 위로하려 해도.\n",
      "\"날 떠나지 마 널 그리워하지 마\"라고 했던 것처럼.\n",
      "\" 문장 비문 여부 온 세상이 지쳐 있단 것을 알면서 더욱 흔들리고.\n",
      "문장 비문 여부.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, pipeline\n",
    "\n",
    "with open(\"../../1.데이터모음/generated_lyrics/generated_lyrics_2025-01-31_07-25-44.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    data = file.read()\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained('j5ng/et5-typos-corrector')\n",
    "tokenizer = T5Tokenizer.from_pretrained('j5ng/et5-typos-corrector')\n",
    "\n",
    "typos_corrector = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=0 if torch.cuda.is_available() else -1,\n",
    "    framework=\"pt\",\n",
    ")\n",
    "\n",
    "for sentence in sentences : \n",
    "    input_text = sentence\n",
    "    output_text = typos_corrector(\"문장 비문 여부 \" + input_text,\n",
    "                max_length=128,\n",
    "                num_beams=5,\n",
    "                early_stopping=True)[0]['generated_text']\n",
    "    print(output_text) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29f699378f304abca9ed80e75c67057d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/263 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95392e8fb56b40ba9a3d6b37aee218e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/77.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'KoBertTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb92f533337a41d8bedc031097337e14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/426 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d854bd0e04ab41d684847e8c2d5a4277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/369M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'부적합 확률': 0.41433313488960266, '적합 확률': 0.585666835308075}\n",
      "{'부적합 확률': 0.4417235553264618, '적합 확률': 0.5582764744758606}\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# KoBERT 모델 로드\n",
    "model_name = \"monologg/kobert\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)  # 0: 부적합, 1: 적합\n",
    "\n",
    "def evaluate_sentence(sentence):\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    score = torch.softmax(logits, dim=1).tolist()[0]\n",
    "    return {\"부적합 확률\": score[0], \"적합 확률\": score[1]}\n",
    "\n",
    "# 테스트 문장\n",
    "print(evaluate_sentence(\"이 문장은 문법적으로 올바른 문장입니다.\"))\n",
    "print(evaluate_sentence(\"문장 완성 않음 이유 때문에.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'KoBertTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'부적합 확률': 0.5395811200141907, '적합 확률': 0.46041879057884216}\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "#데이터 불러오기\n",
    "with open(\"../../1.데이터모음/generated_lyrics/generated_lyrics_2025-01-31_07-25-44.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    data = file.read()\n",
    "\n",
    "# KoBERT 모델 로드\n",
    "model_name = \"monologg/kobert\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)  # 0: 부적합, 1: 적합\n",
    "\n",
    "def evaluate_sentence(sentence):\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    score = torch.softmax(logits, dim=1).tolist()[0]\n",
    "    return {\"부적합 확률\": score[0], \"적합 확률\": score[1]}\n",
    "\n",
    "# 테스트 문장\n",
    "print(evaluate_sentence(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "team5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
